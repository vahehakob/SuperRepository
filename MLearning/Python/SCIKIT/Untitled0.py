
# In[71]:

import pandas as pd
import json
import numpy as np
import pylab as pl
import itertools
from sklearn import linear_model, datasets
from sklearn.decomposition import PCA


# In[72]:

'''
    load data
'''
file_ = 'adsquare_teaser_dataMay2014.json'
fp = open(file_)
data = json.load(fp)
dframe = pd.DataFrame( data )
print dframe.describe()


# Out[72]:

#               Earning       Index          X1          X2          X3          X4          X5       Zeta
#     count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  26.000000
#     mean    68.987725   49.500000   11.036567    3.429383    1.066958   -1.625202    6.665725   0.008950
#     std    207.069287   29.011492    6.639703    9.099960    1.611464   12.649626    8.888543   3.178287
#     min   -441.872612    0.000000   -2.868187  -13.615200   -1.909986  -23.268849  -16.501386  -5.737756
#     25%    -53.370111   24.750000    6.166075   -3.367730   -0.202271  -12.698001    0.451811  -2.118379
#     50%     71.848425   49.500000   11.110337    2.057958    1.236681   -2.898435    7.078727  -0.531868
#     75%    206.180674   74.250000   16.332492   11.564573    2.064181    9.628537   12.921400   1.479583
#     max    485.608414   99.000000   23.837957   23.377158    5.298393   23.530120   24.825712   6.653498
#     

#     C:\Python27\lib\site-packages\pandas\core\config.py:570: DeprecationWarning: height has been deprecated.
#     
#       warnings.warn(d.msg, DeprecationWarning)
#     

# In[85]:

'''
    1D plot histo
'''
pl.figure(1)
pl.hist(np.array(dframe['X1']))
pl.figure(2)
pl.hist(np.array(dframe['X2']))
pl.figure(3)
pl.hist(np.array(dframe['X3']))
pl.figure(4)
pl.hist(np.array(dframe['X4']))
pl.figure(5)
pl.hist(np.array(dframe['X5']))
pl.show()


# In[86]:

'''
    2D plots
'''
X_headers = ['X1','X2','X3','X4','X5','Zeta']
Y = np.array(dframe['Earning'])
pl.figure(1)
X = np.array(dframe['X1'])
pl.plot(X,Y,"o")
pl.figure(2)
X = np.array(dframe['X2'])
pl.plot(X,Y,"x")
pl.figure(3)
X = np.array(dframe['X3'])
pl.plot(X,Y,"*")
pl.figure(4)
X = np.array(dframe['X4'])
pl.plot(X,Y,"v")
pl.figure(5)
X = np.array(dframe['X5'])
pl.plot(X,Y,"s")
pl.show()


# In[92]:

'''
    X data against X data
'''
X1 = np.array(dframe['X1'])
X2 = np.array(dframe['X2'])
X3 = np.array(dframe['X3'])
X4 = np.array(dframe['X4'])
X5 = np.array(dframe['X5'])
pl.clf()
pl.figure(1)
pl.plot(X1,X2,"o")
pl.figure(2)
pl.plot(X1,X3,"o")
pl.figure(3)
pl.plot(X1,X4,"o")
pl.figure(4)
pl.plot(X1,X5,"o")
pl.figure(5)
pl.plot(X2,X3,"o")
pl.figure(6)
pl.plot(X2,X4,"o")
pl.figure(7)
pl.plot(X2,X5,"o")
pl.figure(8)
pl.plot(X3,X4,"o")
pl.figure(9)
pl.plot(X3,X5,"o")
pl.figure(10)
pl.plot(X4,X5,"o")
pl.show()


# In[100]:

'''
    Check wether data correlated
'''
from scipy.stats.stats import pearsonr   
print '12',np.sqrt(pearsonr(X1,X2)[0]**2+pearsonr(X1,X2)[1]**2)#, np.corrcoef(X1,X2)
print '13',np.sqrt(pearsonr(X1,X3)[0]**2+pearsonr(X1,X3)[1]**2)
print '14',np.sqrt(pearsonr(X1,X4)[0]**2+pearsonr(X1,X4)[1]**2)
print '15',np.sqrt(pearsonr(X1,X5)[0]**2+pearsonr(X1,X5)[1]**2)
print '23',np.sqrt(pearsonr(X2,X3)[0]**2+pearsonr(X2,X3)[1]**2)
print '24',np.sqrt(pearsonr(X2,X4)[0]**2+pearsonr(X2,X4)[1]**2)
print '25',np.sqrt(pearsonr(X2,X5)[0]**2+pearsonr(X2,X5)[1]**2)
print '34',np.sqrt(pearsonr(X3,X4)[0]**2+pearsonr(X3,X4)[1]**2)
print '35',np.sqrt(pearsonr(X3,X5)[0]**2+pearsonr(X3,X5)[1]**2)
print '45',np.sqrt(pearsonr(X4,X5)[0]**2+pearsonr(X4,X5)[1]**2)


# Out[100]:

#     12 0.303496844628
#     13 0.193780324854
#     14 0.573709270889
#     15 0.507198391964
#     23 0.734109658079
#     24 0.590539735611
#     25 0.263633048883
#     34 0.490855282513
#     35 0.203637355099
#     45 0.643864217983
#     

# In[ ]:




# In[69]:

file_ = 'adsquare_teaser_dataMay2014.json'
fp = open(file_)
data = json.load(fp)
dframe = pd.DataFrame( data )
print dframe.describe()

X_headers = ['X1','X2','X3','X4','X5']
Y = np.array(dframe['Earning'])

pca = PCA(n_components=1)
pca.fit(X)
print len(pca.transform(X))
#print pca.X_new
print pca.get_params(deep=True)
#print pca.
#print pca.whiten()
#PCA(copy=True, n_components=3, whiten=False)
#print pca.explained_variance_ratio_ #, pca.transform(X)
#print pca.components_


# Out[69]:

#               Earning       Index          X1          X2          X3          X4          X5       Zeta
#     count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  26.000000
#     mean    68.987725   49.500000   11.036567    3.429383    1.066958   -1.625202    6.665725   0.008950
#     std    207.069287   29.011492    6.639703    9.099960    1.611464   12.649626    8.888543   3.178287
#     min   -441.872612    0.000000   -2.868187  -13.615200   -1.909986  -23.268849  -16.501386  -5.737756
#     25%    -53.370111   24.750000    6.166075   -3.367730   -0.202271  -12.698001    0.451811  -2.118379
#     50%     71.848425   49.500000   11.110337    2.057958    1.236681   -2.898435    7.078727  -0.531868
#     75%    206.180674   74.250000   16.332492   11.564573    2.064181    9.628537   12.921400   1.479583
#     max    485.608414   99.000000   23.837957   23.377158    5.298393   23.530120   24.825712   6.653498
#     6
#     {'copy': True, 'n_components': 1, 'whiten': False}
#     

#     C:\Python27\lib\site-packages\pandas\core\config.py:570: DeprecationWarning: height has been deprecated.
#     
#       warnings.warn(d.msg, DeprecationWarning)
#     

# In[ ]:




# In[34]:

file_ = 'adsquare_teaser_dataMay2014.json'
fp = open(file_)

data = json.load(fp) #[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]])
dframe = pd.DataFrame( data )
X_headers = ['X1','X2','X3','X4','X5']
Y = np.array(dframe['Earning'])

print Y[:3] 
print X[:3]
regr = linear_model.LinearRegression()
regr.fit(X, Y)
print label, ' --*-- ' ,regr.score(X,Y)
for size in xrange(2,5):
    for i in itertools.permutations(X_headers, size):  
        X = np.array(dframe[list(i)])
        regr = linear_model.LinearRegression()
        regr.fit(X, Y)
        if (regr.score(X,Y) > 0.65):
            print size, list(i), ' -*- ' ,regr.score(X,Y)
            
X = np.array(dframe[['X1','X2','X3','X4','X5']])
regr = linear_model.LinearRegression()
regr.fit(X, Y)
print size, list(i), ' -*- ' ,regr.score(X,Y)
'''
print dframe.head()
df = dframe[['X1','X2','X3','X4','X5']]
print type(df),df.head()
#for i in  df:
#    print i, type(i)
X = np.array(df)
regr = linear_model.LinearRegression()
regr.fit(X, Y)
regr.score(X, Y)
'''
'''
for label in ['X1','X2','X3','X4','X5']:
    X = np.array(dframe[label])
    Y = np.array(dframe['Earning'])
    regr = linear_model.LinearRegression()
    regr.fit(X, Y)
    print label, ' -*- ' ,regr.score(X,Y)
#print type(np.array(dframe['X1','X2','X3','X4','X5'])) #.head(25)))
#dframe.tail()
'''

#regr = linear_model.LinearRegression()
#regr.fit(diabetes_X_train, diabetes_y_train)
#LinearRegression(copy_X=True, fit_intercept=True, normalize=False)


# Out[34]:

#     [-220.974098  221.004807  141.888054]
#     [[ 11.255087   1.38802    2.944195  16.699407  -4.294483]
#      [  9.330658  15.812443   2.145769   4.27098   24.825712]
#      [  9.477666  -5.99551    1.585362   5.2289    12.033579]]
#     X1  --*--  0.702094667987
#     2 ['X2', 'X4']  -*-  0.684973860474
#     2 ['X4', 'X2']  -*-  0.684973860474
#     2 ['X4', 'X5']  -*-  0.652035966075
#     2 ['X5', 'X4']  -*-  0.652035966075
#     3 ['X1', 'X2', 'X4']  -*-  0.685812189853
#     3 ['X1', 'X4', 'X2']  -*-  0.685812189853
#     3 ['X1', 'X4', 'X5']  -*-  0.652036334622
#     3 ['X1', 'X5', 'X4']  -*-  0.652036334622
#     3 ['X2', 'X1', 'X4']  -*-  0.685812189853
#     3 ['X2', 'X3', 'X4']  -*-  0.687287297667
#     3 ['X2', 'X4', 'X1']  -*-  0.685812189853
#     3 ['X2', 'X4', 'X3']  -*-  0.687287297667
#     3 ['X2', 'X4', 'X5']  -*-  0.697618995793
#     3 ['X2', 'X5', 'X4']  -*-  0.697618995793
#     3 ['X3', 'X2', 'X4']  -*-  0.687287297667
#     3 ['X3', 'X4', 'X2']  -*-  0.687287297667
#     3 ['X3', 'X4', 'X5']  -*-  0.655082564077
#     3 ['X3', 'X5', 'X4']  -*-  0.655082564077
#     3 ['X4', 'X1', 'X2']  -*-  0.685812189853
#     3 ['X4', 'X1', 'X5']  -*-  0.652036334622
#     3 ['X4', 'X2', 'X1']  -*-  0.685812189853
#     3 ['X4', 'X2', 'X3']  -*-  0.687287297667
#     3 ['X4', 'X2', 'X5']  -*-  0.697618995793
#     3 ['X4', 'X3', 'X2']  -*-  0.687287297667
#     3 ['X4', 'X3', 'X5']  -*-  0.655082564077
#     3 ['X4', 'X5', 'X1']  -*-  0.652036334622
#     3 ['X4', 'X5', 'X2']  -*-  0.697618995793
#     3 ['X4', 'X5', 'X3']  -*-  0.655082564077
#     3 ['X5', 'X1', 'X4']  -*-  0.652036334622
#     3 ['X5', 'X2', 'X4']  -*-  0.697618995793
#     3 ['X5', 'X3', 'X4']  -*-  0.655082564077
#     3 ['X5', 'X4', 'X1']  -*-  0.652036334622
#     3 ['X5', 'X4', 'X2']  -*-  0.697618995793
#     3 ['X5', 'X4', 'X3']  -*-  0.655082564077
#     4 ['X1', 'X2', 'X3', 'X4']  -*-  0.687739418486
#     4 ['X1', 'X2', 'X4', 'X3']  -*-  0.687739418486
#     4 ['X1', 'X2', 'X4', 'X5']  -*-  0.698152882847
#     4 ['X1', 'X2', 'X5', 'X4']  -*-  0.698152882847
#     4 ['X1', 'X3', 'X2', 'X4']  -*-  0.687739418486
#     4 ['X1', 'X3', 'X4', 'X2']  -*-  0.687739418486
#     4 ['X1', 'X3', 'X4', 'X5']  -*-  0.65517274242
#     4 ['X1', 'X3', 'X5', 'X4']  -*-  0.65517274242
#     4 ['X1', 'X4', 'X2', 'X3']  -*-  0.687739418486
#     4 ['X1', 'X4', 'X2', 'X5']  -*-  0.698152882847
#     4 ['X1', 'X4', 'X3', 'X2']  -*-  0.687739418486
#     4 ['X1', 'X4', 'X3', 'X5']  -*-  0.65517274242
#     4 ['X1', 'X4', 'X5', 'X2']  -*-  0.698152882847
#     4 ['X1', 'X4', 'X5', 'X3']  -*-  0.65517274242
#     4 ['X1', 'X5', 'X2', 'X4']  -*-  0.698152882847
#     4 ['X1', 'X5', 'X3', 'X4']  -*-  0.65517274242
#     4 ['X1', 'X5', 'X4', 'X2']  -*-  0.698152882847
#     4 ['X1', 'X5', 'X4', 'X3']  -*-  0.65517274242
#     4 ['X2', 'X1', 'X3', 'X4']  -*-  0.687739418486
#     4 ['X2', 'X1', 'X4', 'X3']  -*-  0.687739418486
#     4 ['X2', 'X1', 'X4', 'X5']  -*-  0.698152882847
#     4 ['X2', 'X1', 'X5', 'X4']  -*-  0.698152882847
#     4 ['X2', 'X3', 'X1', 'X4']  -*-  0.687739418486
#     4 ['X2', 'X3', 'X4', 'X1']  -*-  0.687739418486
#     4 ['X2', 'X3', 'X4', 'X5']  -*-  0.701958218538
#     4 ['X2', 'X3', 'X5', 'X4']  -*-  0.701958218538
#     4 ['X2', 'X4', 'X1', 'X3']  -*-  0.687739418486
#     4 ['X2', 'X4', 'X1', 'X5']  -*-  0.698152882847
#     4 ['X2', 'X4', 'X3', 'X1']  -*-  0.687739418486
#     4 ['X2', 'X4', 'X3', 'X5']  -*-  0.701958218538
#     4 ['X2', 'X4', 'X5', 'X1']  -*-  0.698152882847
#     4 ['X2', 'X4', 'X5', 'X3']  -*-  0.701958218538
#     4 ['X2', 'X5', 'X1', 'X4']  -*-  0.698152882847
#     4 ['X2', 'X5', 'X3', 'X4']  -*-  0.701958218538
#     4 ['X2', 'X5', 'X4', 'X1']  -*-  0.698152882847
#     4 ['X2', 'X5', 'X4', 'X3']  -*-  0.701958218538
#     4 ['X3', 'X1', 'X2', 'X4']  -*-  0.687739418486
#     4 ['X3', 'X1', 'X4', 'X2']  -*-  0.687739418486
#     4 ['X3', 'X1', 'X4', 'X5']  -*-  0.65517274242
#     4 ['X3', 'X1', 'X5', 'X4']  -*-  0.65517274242
#     4 ['X3', 'X2', 'X1', 'X4']  -*-  0.687739418486
#     4 ['X3', 'X2', 'X4', 'X1']  -*-  0.687739418486
#     4 ['X3', 'X2', 'X4', 'X5']  -*-  0.701958218538
#     4 ['X3', 'X2', 'X5', 'X4']  -*-  0.701958218538
#     4 ['X3', 'X4', 'X1', 'X2']  -*-  0.687739418486
#     4 ['X3', 'X4', 'X1', 'X5']  -*-  0.65517274242
#     4 ['X3', 'X4', 'X2', 'X1']  -*-  0.687739418486
#     4 ['X3', 'X4', 'X2', 'X5']  -*-  0.701958218538
#     4 ['X3', 'X4', 'X5', 'X1']  -*-  0.65517274242
#     4 ['X3', 'X4', 'X5', 'X2']  -*-  0.701958218538
#     4 ['X3', 'X5', 'X1', 'X4']  -*-  0.65517274242
#     4 ['X3', 'X5', 'X2', 'X4']  -*-  0.701958218538
#     4 ['X3', 'X5', 'X4', 'X1']  -*-  0.65517274242
#     4 ['X3', 'X5', 'X4', 'X2']  -*-  0.701958218538
#     4 ['X4', 'X1', 'X2', 'X3']  -*-  0.687739418486
#     4 ['X4', 'X1', 'X2', 'X5']  -*-  0.698152882847
#     4 ['X4', 'X1', 'X3', 'X2']  -*-  0.687739418486
#     4 ['X4', 'X1', 'X3', 'X5']  -*-  0.65517274242
#     4 ['X4', 'X1', 'X5', 'X2']  -*-  0.698152882847
#     4 ['X4', 'X1', 'X5', 'X3']  -*-  0.65517274242
#     4 ['X4', 'X2', 'X1', 'X3']  -*-  0.687739418486
#     4 ['X4', 'X2', 'X1', 'X5']  -*-  0.698152882847
#     4 ['X4', 'X2', 'X3', 'X1']  -*-  0.687739418486
#     4 ['X4', 'X2', 'X3', 'X5']  -*-  0.701958218538
#     4 ['X4', 'X2', 'X5', 'X1']  -*-  0.698152882847
#     4 ['X4', 'X2', 'X5', 'X3']  -*-  0.701958218538
#     4 ['X4', 'X3', 'X1', 'X2']  -*-  0.687739418486
#     4 ['X4', 'X3', 'X1', 'X5']  -*-  0.65517274242
#     4 ['X4', 'X3', 'X2', 'X1']  -*-  0.687739418486
#     4 ['X4', 'X3', 'X2', 'X5']  -*-  0.701958218538
#     4 ['X4', 'X3', 'X5', 'X1']  -*-  0.65517274242
#     4 ['X4', 'X3', 'X5', 'X2']  -*-  0.701958218538
#     4 ['X4', 'X5', 'X1', 'X2']  -*-  0.698152882847
#     4 ['X4', 'X5', 'X1', 'X3']  -*-  0.65517274242
#     4 ['X4', 'X5', 'X2', 'X1']  -*-  0.698152882847
#     4 ['X4', 'X5', 'X2', 'X3']  -*-  0.701958218538
#     4 ['X4', 'X5', 'X3', 'X1']  -*-  0.65517274242
#     4 ['X4', 'X5', 'X3', 'X2']  -*-  0.701958218538
#     4 ['X5', 'X1', 'X2', 'X4']  -*-  0.698152882847
#     4 ['X5', 'X1', 'X3', 'X4']  -*-  0.65517274242
#     4 ['X5', 'X1', 'X4', 'X2']  -*-  0.698152882847
#     4 ['X5', 'X1', 'X4', 'X3']  -*-  0.65517274242
#     4 ['X5', 'X2', 'X1', 'X4']  -*-  0.698152882847
#     4 ['X5', 'X2', 'X3', 'X4']  -*-  0.701958218538
#     4 ['X5', 'X2', 'X4', 'X1']  -*-  0.698152882847
#     4 ['X5', 'X2', 'X4', 'X3']  -*-  0.701958218538
#     4 ['X5', 'X3', 'X1', 'X4']  -*-  0.65517274242
#     4 ['X5', 'X3', 'X2', 'X4']  -*-  0.701958218538
#     4 ['X5', 'X3', 'X4', 'X1']  -*-  0.65517274242
#     4 ['X5', 'X3', 'X4', 'X2']  -*-  0.701958218538
#     4 ['X5', 'X4', 'X1', 'X2']  -*-  0.698152882847
#     4 ['X5', 'X4', 'X1', 'X3']  -*-  0.65517274242
#     4 ['X5', 'X4', 'X2', 'X1']  -*-  0.698152882847
#     4 ['X5', 'X4', 'X2', 'X3']  -*-  0.701958218538
#     4 ['X5', 'X4', 'X3', 'X1']  -*-  0.65517274242
#     4 ['X5', 'X4', 'X3', 'X2']  -*-  0.701958218538
#     4 ['X5', 'X4', 'X3', 'X2']  -*-  0.702094667987
#     

#     "\nfor label in ['X1','X2','X3','X4','X5']:\n    X = np.array(dframe[label])\n    Y = np.array(dframe['Earning'])\n    regr = linear_model.LinearRegression()\n    regr.fit(X, Y)\n    print label, ' -*- ' ,regr.score(X,Y)\n#print type(np.array(dframe['X1','X2','X3','X4','X5'])) #.head(25)))\n#dframe.tail()\n"

# In[3]:

iris = datasets.load_iris()
iris_X = iris.data
print type(iris_X), iris_X


# Out[3]:

#     <type 'numpy.ndarray'> [[ 5.1  3.5  1.4  0.2]
#      [ 4.9  3.   1.4  0.2]
#      [ 4.7  3.2  1.3  0.2]
#      [ 4.6  3.1  1.5  0.2]
#      [ 5.   3.6  1.4  0.2]
#      [ 5.4  3.9  1.7  0.4]
#      [ 4.6  3.4  1.4  0.3]
#      [ 5.   3.4  1.5  0.2]
#      [ 4.4  2.9  1.4  0.2]
#      [ 4.9  3.1  1.5  0.1]
#      [ 5.4  3.7  1.5  0.2]
#      [ 4.8  3.4  1.6  0.2]
#      [ 4.8  3.   1.4  0.1]
#      [ 4.3  3.   1.1  0.1]
#      [ 5.8  4.   1.2  0.2]
#      [ 5.7  4.4  1.5  0.4]
#      [ 5.4  3.9  1.3  0.4]
#      [ 5.1  3.5  1.4  0.3]
#      [ 5.7  3.8  1.7  0.3]
#      [ 5.1  3.8  1.5  0.3]
#      [ 5.4  3.4  1.7  0.2]
#      [ 5.1  3.7  1.5  0.4]
#      [ 4.6  3.6  1.   0.2]
#      [ 5.1  3.3  1.7  0.5]
#      [ 4.8  3.4  1.9  0.2]
#      [ 5.   3.   1.6  0.2]
#      [ 5.   3.4  1.6  0.4]
#      [ 5.2  3.5  1.5  0.2]
#      [ 5.2  3.4  1.4  0.2]
#      [ 4.7  3.2  1.6  0.2]
#      [ 4.8  3.1  1.6  0.2]
#      [ 5.4  3.4  1.5  0.4]
#      [ 5.2  4.1  1.5  0.1]
#      [ 5.5  4.2  1.4  0.2]
#      [ 4.9  3.1  1.5  0.1]
#      [ 5.   3.2  1.2  0.2]
#      [ 5.5  3.5  1.3  0.2]
#      [ 4.9  3.1  1.5  0.1]
#      [ 4.4  3.   1.3  0.2]
#      [ 5.1  3.4  1.5  0.2]
#      [ 5.   3.5  1.3  0.3]
#      [ 4.5  2.3  1.3  0.3]
#      [ 4.4  3.2  1.3  0.2]
#      [ 5.   3.5  1.6  0.6]
#      [ 5.1  3.8  1.9  0.4]
#      [ 4.8  3.   1.4  0.3]
#      [ 5.1  3.8  1.6  0.2]
#      [ 4.6  3.2  1.4  0.2]
#      [ 5.3  3.7  1.5  0.2]
#      [ 5.   3.3  1.4  0.2]
#      [ 7.   3.2  4.7  1.4]
#      [ 6.4  3.2  4.5  1.5]
#      [ 6.9  3.1  4.9  1.5]
#      [ 5.5  2.3  4.   1.3]
#      [ 6.5  2.8  4.6  1.5]
#      [ 5.7  2.8  4.5  1.3]
#      [ 6.3  3.3  4.7  1.6]
#      [ 4.9  2.4  3.3  1. ]
#      [ 6.6  2.9  4.6  1.3]
#      [ 5.2  2.7  3.9  1.4]
#      [ 5.   2.   3.5  1. ]
#      [ 5.9  3.   4.2  1.5]
#      [ 6.   2.2  4.   1. ]
#      [ 6.1  2.9  4.7  1.4]
#      [ 5.6  2.9  3.6  1.3]
#      [ 6.7  3.1  4.4  1.4]
#      [ 5.6  3.   4.5  1.5]
#      [ 5.8  2.7  4.1  1. ]
#      [ 6.2  2.2  4.5  1.5]
#      [ 5.6  2.5  3.9  1.1]
#      [ 5.9  3.2  4.8  1.8]
#      [ 6.1  2.8  4.   1.3]
#      [ 6.3  2.5  4.9  1.5]
#      [ 6.1  2.8  4.7  1.2]
#      [ 6.4  2.9  4.3  1.3]
#      [ 6.6  3.   4.4  1.4]
#      [ 6.8  2.8  4.8  1.4]
#      [ 6.7  3.   5.   1.7]
#      [ 6.   2.9  4.5  1.5]
#      [ 5.7  2.6  3.5  1. ]
#      [ 5.5  2.4  3.8  1.1]
#      [ 5.5  2.4  3.7  1. ]
#      [ 5.8  2.7  3.9  1.2]
#      [ 6.   2.7  5.1  1.6]
#      [ 5.4  3.   4.5  1.5]
#      [ 6.   3.4  4.5  1.6]
#      [ 6.7  3.1  4.7  1.5]
#      [ 6.3  2.3  4.4  1.3]
#      [ 5.6  3.   4.1  1.3]
#      [ 5.5  2.5  4.   1.3]
#      [ 5.5  2.6  4.4  1.2]
#      [ 6.1  3.   4.6  1.4]
#      [ 5.8  2.6  4.   1.2]
#      [ 5.   2.3  3.3  1. ]
#      [ 5.6  2.7  4.2  1.3]
#      [ 5.7  3.   4.2  1.2]
#      [ 5.7  2.9  4.2  1.3]
#      [ 6.2  2.9  4.3  1.3]
#      [ 5.1  2.5  3.   1.1]
#      [ 5.7  2.8  4.1  1.3]
#      [ 6.3  3.3  6.   2.5]
#      [ 5.8  2.7  5.1  1.9]
#      [ 7.1  3.   5.9  2.1]
#      [ 6.3  2.9  5.6  1.8]
#      [ 6.5  3.   5.8  2.2]
#      [ 7.6  3.   6.6  2.1]
#      [ 4.9  2.5  4.5  1.7]
#      [ 7.3  2.9  6.3  1.8]
#      [ 6.7  2.5  5.8  1.8]
#      [ 7.2  3.6  6.1  2.5]
#      [ 6.5  3.2  5.1  2. ]
#      [ 6.4  2.7  5.3  1.9]
#      [ 6.8  3.   5.5  2.1]
#      [ 5.7  2.5  5.   2. ]
#      [ 5.8  2.8  5.1  2.4]
#      [ 6.4  3.2  5.3  2.3]
#      [ 6.5  3.   5.5  1.8]
#      [ 7.7  3.8  6.7  2.2]
#      [ 7.7  2.6  6.9  2.3]
#      [ 6.   2.2  5.   1.5]
#      [ 6.9  3.2  5.7  2.3]
#      [ 5.6  2.8  4.9  2. ]
#      [ 7.7  2.8  6.7  2. ]
#      [ 6.3  2.7  4.9  1.8]
#      [ 6.7  3.3  5.7  2.1]
#      [ 7.2  3.2  6.   1.8]
#      [ 6.2  2.8  4.8  1.8]
#      [ 6.1  3.   4.9  1.8]
#      [ 6.4  2.8  5.6  2.1]
#      [ 7.2  3.   5.8  1.6]
#      [ 7.4  2.8  6.1  1.9]
#      [ 7.9  3.8  6.4  2. ]
#      [ 6.4  2.8  5.6  2.2]
#      [ 6.3  2.8  5.1  1.5]
#      [ 6.1  2.6  5.6  1.4]
#      [ 7.7  3.   6.1  2.3]
#      [ 6.3  3.4  5.6  2.4]
#      [ 6.4  3.1  5.5  1.8]
#      [ 6.   3.   4.8  1.8]
#      [ 6.9  3.1  5.4  2.1]
#      [ 6.7  3.1  5.6  2.4]
#      [ 6.9  3.1  5.1  2.3]
#      [ 5.8  2.7  5.1  1.9]
#      [ 6.8  3.2  5.9  2.3]
#      [ 6.7  3.3  5.7  2.5]
#      [ 6.7  3.   5.2  2.3]
#      [ 6.3  2.5  5.   1.9]
#      [ 6.5  3.   5.2  2. ]
#      [ 6.2  3.4  5.4  2.3]
#      [ 5.9  3.   5.1  1.8]]
#     

# In[ ]:



